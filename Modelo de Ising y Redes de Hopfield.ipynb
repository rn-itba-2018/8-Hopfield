{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Ising y redes de Hopfield\n",
    "\n",
    "Las contribuciones mas importantes que hizo John Hopfield al modelo de memoria asociativa visto anteriormente surgen a que dicho modelo es casi idéntico matemáticamente al problema de Ising. \n",
    "\n",
    "El modelo de Ising es un modelo físico propuesto para estudiar el comportamiento de materiales ferromagnéticos.  Su nombre se debe al físico Ernst Ising.\n",
    "\n",
    "Hopfield estableción un analogía entre el modelo de memoria asociativa y el de Ising, trasladando algunas propiedades matemáticas del ya conocido modelo de Ising al problema de la memoria asociativa. Es por ello que nos vamos a detener a mirar, aunque sea superficialmente, algunas de las particularidades del modelo de Ising.\n",
    "\n",
    "Para un material ferromagnético:\n",
    "\n",
    "- Se pueden representar como un conjunto de dipolos magnéticos de tamaño atómico, dispuestos de acuerdo a una estructura cristalina. A cada dipolo lo llamaremos SPIN.\n",
    "- Cada spin podrá estar alineado en dos direcciones posibles.\n",
    "- cada spin será identificado por una variable $S_i$. Si el spin i está orientado hacia arriba, entonces $S_i=1$. Si el spin i está orientado hacia abajo $S_i=-1$\n",
    "- La representación gráfica de un material ferromagnético de 4 spins nos quedará de la siguiente forma:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Ising-rep.png\" alt=\"drawing\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para la red neuronal análoga, una neurona activada equivale a un spin +1 y una neurona desactivada un spin -1.\n",
    "\n",
    "* El comportamiento de cada spin queda definido por el campo magnético existente en su ubicación, el cual está compuesto por el campo generado por los otros spins (campo interno), mas la contribución de un posible campo magnético externo.\n",
    "* Dichas contribuciones sobre el spin i pueden ser expresadas como:\n",
    "\\begin{equation} \n",
    "h_i =   \\sum_{j} w_{ij} S_{j}+ h^{ext}\n",
    "\\end{equation}\n",
    "    * Donde cada coeficiente $w_{ij}$ miden la influencia de cada spin j sobre el spin i. En un material magnético estos coeficientes son simétricos.\n",
    "* El campo magnético $h_i$ a bajas temperaturas define la dinámica del spin i ya que el spin tiende a alinearse según la dirección de $h_i$.\n",
    "   * Por lo tanto el valor de $S_i = sgn(h_i)$\n",
    "* Otra forma de definir la interacción de los spins es a través de la energía potencial vinculada a esa interacción. Para un material magnético cuyos spins están influenciados según $\\omega_{ij}$, su energía potencial es:\n",
    "\\begin{equation} \n",
    "H =  -\\frac{1}{2} \\sum_{ij} w_{ij} S_{i}S_{j}- h^{ext}\\sum_{i}S_i\n",
    "\\end{equation}\n",
    "* Por lo tanto la analogía con una red de Hopfield es completa\n",
    "   * Los coeficientes de interacción entre los spins son los pesos\n",
    "   * La entrada a una neurona corresponde al estado de cada uno de los spins.\n",
    "   * La suma resultante de la interacción de todos los spins j en un spin i mas el campo externo, corresponde a la salida del combinador lineal.\n",
    "* Se puede pensar que cada vez que agrego un patrón a un a red de hopfield, estoy agregando un nuevo mínimo a la función de energía (mas otros mínimos que aparecen como estados espurios almacenados).\n",
    "* Otra propiedad de la función de energía en el modelo de Ising es que cada vez que actualizo un spin en particular en forma asincrónica, la energía se mantiene o disminuye. En particular para el modelo de Ising $w_{ii}=0$.\n",
    "    * Si actualizo $S_k$ y $S_k^{t+1}=S_k^{t}$: La energía se mantiene constante\n",
    "    * Si actualizo $S_k$ y $S_k^{t+1}=-S_k^{t}$:\n",
    "$$ H^{t+1}-H^{t}= -\\frac{1}{2} \\sum_{i} w_{ik} S_{i}S_{k}^{t+1} -\\frac{1}{2} \\sum_{j} w_{kj} S_{k}^{t+1}S_{j}- h^{ext}S_k^{t+1} +\\frac{1}{2} \\sum_{i} w_{ik} S_{i}S_{k}^{t} +\\frac{1}{2} \\sum_{j} w_{kj} S_{k}^{t}S_{j}+ h^{ext}S_k^{t} $$\n",
    "$$ =-\\sum_{i} w_{ik} S_{i}S_{k}^{t+1} - h^{ext}S_k^{t+1}+\\sum_{i} w_{ik} S_{i}S_{k}^{t}+h^{ext}S_k^{t} $$\n",
    "        * Como $S_k$ y $S_k^{t+1}=-S_k^{t}$:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H^{t+1}-H^{t}= -S_{k}^{t+1} [\\sum_{i} w_{ik} S_{i} + h^{ext}] + S_{k}^{t} [\\sum_{i} w_{ik} S_{i} + h^{ext}]$$\n",
    "$$  H^{t+1}-H^{t} = (-S_{k}^{t+1} + S_{k}^{t}) [\\sum_{i} w_{ik} S_{i} + h^{ext}] = -2 S_{k}^{t+1} [\\sum_{i} w_{ik} S_{i} + h^{ext}] $$\n",
    "\n",
    "* Como $h_k^{t+1}=\\sum_{i} w_{ik} S_{i} + h^{ext}$, y el signo de $h_k^{t+1}$ va a ser igual al de $S_{k}^{t+1}$, el primer término es siempre negativo ya que $S_{k}^{t+1}*h_k^{t+1}$ es siempre positivo. \n",
    "    * De manera análoga se puede ver que el segundo término también es siempre negativo.\n",
    "    * Por lo tanto, la energía de la red cuando se realiza actualización asincrónica, solo puede mantenerse (el spin no cambió) o disminuir(el spin cambió)\n",
    "    * Además, actualizar en forma sincrónica puede conducir a estados oscilatorio:\n",
    "    \n",
    "    Insertar ejemplo\n",
    "    \n",
    "Una vez vista la analogía con el modelo de Ising, sigamos adelante con el análisis de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estabilidad de un patrón\n",
    "\n",
    "### Condición de estabilidad\n",
    "\n",
    "Normalmente, se espera que si se entrena con un patrón, el mismo debería ser igual a la salida, ya que se entrenó justamente la red para que eso pase. Dicho de otra forma, se debe cumplir:\n",
    "\n",
    "$ sign(h_i^\\nu) = 𝜉_i^\\nu $ para todo i\n",
    "\n",
    "Donde $h_i^\\nu = \\sum_{j} w_{ij}^\\mu 𝜉_j^\\nu$ que es lo que resulta de entrenar la red de hopfield con un patrón ($𝜉$).\n",
    "\n",
    "Desarrollando los pesos $w$ se llega a que:\n",
    "\n",
    "$$ h_i^\\nu = \\frac{1}{N} \\sum_{j}\\sum_{\\mu} 𝜉_{i}^\\mu 𝜉_{j}^{\\mu} 𝜉_j^\\nu $$\n",
    "\n",
    "Sacamos finalmente factor común:\n",
    "\n",
    "\\begin{equation} \n",
    "h_i^\\nu = 𝜉_i^\\nu + \\frac{1}{N} \\sum_{j}\\sum_{\\mu \\neq \\nu} 𝜉_{i}^\\mu 𝜉_{j}^{\\mu} 𝜉_j^\\nu \n",
    "\\end{equation}\n",
    "\n",
    "De la última ecuación se deduce que si el término de la derecha, es nulo, se cumple la condición de estabilidad.\n",
    "De hecho, gracias a la función signo que se debe aplicar sobre $h_i^\\nu$, se puede ser menos restrictivo con el término de la derecha y se puede decir que para que cumpla estabilidad debe darse la siguiente igualdad:\n",
    "\n",
    "\\begin{equation} \n",
    "    -𝜉_i^\\nu \\frac{1}{N} \\sum_{j}\\sum_{\\mu \\neq \\nu} 𝜉_{i}^\\mu 𝜉_{j}^{\\mu} 𝜉_j^\\nu < 1 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacidad de la red\n",
    "\n",
    "Definiremos entonces la siguiente magnitud:\n",
    "\n",
    "$$ C_i^\\nu = 𝜉_i^\\nu \\frac{1}{N} \\sum_{j}\\sum_{\\mu \\neq \\nu} 𝜉_{i}^\\mu 𝜉_{j}^{\\mu} 𝜉_j^\\nu $$\n",
    "\n",
    "De la condición de estabilidad vista anteriormente.\n",
    "Si $ C_i^\\nu > 1 $ entonces tendremos un bit erroneo en la salida. Es decir, si se ingresa a la red con un patrón de entrenamiento, a la salida se obtendrá un patrón distinto al deseado.\n",
    "\n",
    "$ C_i^\\nu $ depende únicamente de los patrones que queremos almacenar y de su cantidad. Si consideramos patrones de entrenamiento con igual ocurrencia de $  𝜉_{i}^\\mu = 1 $ y $  𝜉_{i}^\\mu = -1 $ entonces se puede calcular que la probablidad de que un bit sea inestable es:\n",
    "\n",
    "$$ P_{error} = Prob(C_i^\\nu > 1) $$\n",
    "\n",
    "Calculemos 𝑃_𝑒𝑟𝑟𝑜𝑟:\n",
    "- N es la cantidad de bits de la entrada/salida.\n",
    "- p es la cantidad de patrones almacenados.\n",
    "\n",
    "_Nota:_ Suponemos que N y p >> 1 (es una condición aceptable y simplificará la matemática).\n",
    "\n",
    "$ 𝐶_𝑖^𝜈 $ es 1/N veces la suma de N*p (N*(p-1) para ser exactos) números aleatorios independientes que valen 1 o -1. Distribución de una suma de N*p valores que pueden valer 1 o -1 con p=0.5.\n",
    "\n",
    "Este problema puede ser modelado con una distribución binomial de media cero y varianza $𝜎^2=𝑝/𝑁$, pero por ser una suma de N términos, para $N*p>30$ puede ser modelado con una distribución gaussiana, valiéndonos del Teorema del Límite Central:\n",
    "\n",
    "![gauss](images/gaus.png)\n",
    "\n",
    "La siguiente tabla muestra las relaciones de p/N para obtener distintas probabilidades de error:\n",
    "![gauss](images/tablaerrores.png)\n",
    "\n",
    "Se puede interpretar éstos resultados siendo que cuanto más grandes sean los patrones (N mayor) mayor será la matríz de Hopfield y mayor su capacidad. Por el contrario, cuantos más patrones se deseen agregar (p), más aumentará su probabilidad de error.\n",
    "\n",
    "Elizabeth Gardner demostró en los '80 que el límite teórico de alacenamiento de datos en un patró"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estados Espúrios\n",
    "\n",
    "Además de almacenar un patrón inverso, hay otros patrones que funcionan como atractores. Dicho atractor que no es ni el patrón mismo ni el patrón inverso se lo denomina como estádo espúreo.\n",
    "Un ejemplo de patrón espúreo, surge de hacer la cominación lineal de un número impar de patrones de entrenamiento, por ejemplo:\n",
    "\\begin{equation} \n",
    "𝜉_i^{mix} = sgn(\\pm𝜉_i^{\\mu_1}\\pm𝜉_i^{\\mu_2}\\pm𝜉_i^{\\mu_3})\n",
    "\\end{equation}\n",
    "\n",
    "Para un valor de $𝜉_i^{\\mu_1}$ dado $𝜉_i^{mix}$ tendrá el mismo signo 3 de las 4 combinaciones posibles de $𝜉_i^{\\mu_2}$ y $𝜉_i^{\\mu_3}$ por lo tanto $𝜉_i^{mix}$ estará a una distancia de Hamming N/4 de $𝜉_i^{\\mu_1}$. un razonamiento análogo nos lleva a que la distancia de Hamming de $𝜉_i^{mix}$ con respecto a $𝜉_i^{\\mu_2}$ y $𝜉_i^{\\mu_3}$ también es N/4.\n",
    "\n",
    "Esto implica que el producto escalar entre $𝜉_i^{mix}$ y $𝜉_i^{\\mu_1}$ valga N/2.\n",
    "\n",
    "Por lo tanto, nos queda:\n",
    "\\begin{equation} \n",
    "h_i^{mix} =  \\frac{1}{N} \\sum_{j\\mu} 𝜉_{i}^\\mu 𝜉_{j}^{\\mu} 𝜉_j^{mix} = \\frac{1}{2}𝜉_i^{\\mu_2}+\\frac{1}{2}𝜉_i^{\\mu_3}+crossterms\n",
    "\\end{equation}\n",
    "\n",
    "Los cross-terms tienen la particularidad estadística (distribuación binamial) analizada anteriormente, por lo que la ecuación anterior cumple con el criterio de estabilidad. Por lo tanto $𝜉_i^{mix}$ es un patrón almacenado en la red.\n",
    "\n",
    "Además Amit (1985) demostró que existen otros estados espúreos en la red que no guardan correlación con los estados ya almacenados.\n",
    "\n",
    "Por lo tanto, la red de Hopfield está limitada no solo por la probabilidad del error de bit, sino que admás por la existencia de estados espúreos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efecto de la temperatura en el modelo de Issing\n",
    " - El modelo anterior aplica solamente a temperaturas muy bajas, cercanas al 0 K.\n",
    " - Para temeraturas más altas, el comportamiento de los spins se vuelve estocástico y su estado de alineación esta determinado por: $S_i = +1$ on probabilidad $g(h_i)$ y $S_i$ con probabilidad $1-g(h_i)$.\n",
    " - La función $g(h_i)$ depende de la temperatura del sistema:\n",
    "\\begin{equation} \n",
    "g(h) = f_\\beta(h)\\equiv \\frac{1}{1+exp(-2\\beta h)}\n",
    "\\end{equation}\n",
    " - Ya que $\\beta=\\frac{1}{\\kappa_B T}$, donde $\\kappa_B$ es la constante de Boltzmann y vale $1.38*10^{16\\frac{erg}{K}}$.\n",
    " - Dado que: $1-f_\\beta(h)=f_\\beta(-h)$, podemos escribir: $Prob(S_i = \\pm1)=f_\\beta(\\pm h_i)=\\frac{1}{1+exp(\\mp2\\beta h_i)}$\n",
    " - La temperatura regula qué tan abrupta es la variación de la pdf alrededor de h=0.\n",
    " - A medida que $T\\rightarrow0$, vemos como el modelo estocástico se reduce al modelo determinístico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estado de equilibrio de un spin\n",
    " - Vamos a analizar cual es la magnetización promedio de un material ferromagnético.\n",
    " - Para empezar, supongamos que tenemos un material ferromagnético de un solo spin.\n",
    "   - Esto implicará que el único campo magnético será el externo.\n",
    "   - Su valor promedio tendrá la forma:\n",
    "\\begin{equation}\n",
    "\t\\langle S \\rangle = Prob(+1).(+1)+ Prob(-1).(-1) \\\\\n",
    "    = \\frac{1}{1+e^{-2\\beta h}}-\\frac{1}{1+e^{2\\beta h}}=\\frac{e^{\\beta h}}{e^{\\beta h}+e^{-\\beta h}}-\\frac{e^{-\\beta h}}{e^{-\\beta h}+e^{\\beta h}} \\\\\n",
    "    =tangh(\\beta h)\n",
    "\\end{equation}\n",
    " - La tanh tiene la misma forma que la distribución de probabilidades, pero varia entre -1 y 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teroría del campo medio\n",
    " - Ahora queremos analizar que pasa en un material ferromagnético con más de un spin.\n",
    " - La evolución del estado de un spin i depende de:\n",
    "\\begin{equation}\n",
    " h_i=\\sum_i w_{ij}S_j+h^{ext}\n",
    "\\end{equation}\n",
    "   - Lo cual involucra variables S_j que fluctuán en el tiempo.\n",
    "  - Como el análisis de un material ferromagnético es muy complejo, se utiliza la teoría del campo medio para analizar el comportamiento de material y su magnetización promedio.\n",
    "  - Más allá del interés que pueda tener físicamente este análisis, más adelante noss brindará una herramienta más para analizar redes neuoronales.\n",
    "  - La idea consiste en reemplazar a cada uno de los $h_i$ resultantes en  cada spin, por su valor medio:\n",
    "  \\begin{equation}\n",
    "\t\\langle h_i \\rangle =\\sum_j w_{ij}\\langle S_j \\rangle + h^{ext}\n",
    "   \\end{equation}\n",
    "  - El mismo depende de los valores promedios de los spins del material.\n",
    "  - A partir de lo visto en \"Esta de equilibrio de un spin\" podemos calcular los valores de campo magnético de cada spin del material como:\n",
    "  \\begin{equation}\n",
    "\t\\langle S_i \\rangle = tanh(\\beta \\langle h_i \\rangle) = tanh(\\beta\\sum_j w_{ij}\\langle S_j \\rangle +\\beta h^{ext})\n",
    "  \\end{equation}\n",
    "    - Lo cual nos da N ecuaciones no lineales con N incógnitas, pero sin que en ningún lado aparezcan variables aleatorias.\n",
    "  - La idea es reemplazar todos los spins salvo por sus valores medios, de esta forma podemos analizar como evoluciona un spin en particular.\n",
    "  - A medida que la cantidad de spins aumenta, este modelo se vuelve cada vez más preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Material ferromagnético\n",
    " - Todos los $w_{ij}$ son positivos. Esto hace que todos los spins tiendan a alinearse los unos a los otros.\n",
    " - A partir de cierta temperatura $T_C$, sin campo externo,$\\langle S \\rangle =0$. Por debajo de esa temperatura $T_C,\\langle S \\rangle \\neq 0$\n",
    "   - Por ejemplo el hierro pierde sus propiedades magnéticas a 770 grados.\n",
    " - El modelo más sencillo de material ferromagnético está dado por $w_{ij}=\\frac{J}{N}$\n",
    "   - Para un ferromagnético de N spins.\n",
    "   - Este modelo tiene su análogo en la red de Hopfield. Si J=1, corresponde a un solo patrón almacenado, cuyos bits valen todos 1.\n",
    "   - Es decir. hay dos atractores, uno con todos los valores en 1 y otro con todos los valores en -1. Dicho de otra forma, todos los spins alineados hacia arriaba y todos los spins alineados hacia abajo.\n",
    "   - Si hablamos de una red con varios patrones almacenados, el fenómeno es como si habláramos de un material ferromagnético cuyos valores de spins estables ya no son todos 1 o todos -1, sino que aparecen otras opciones.\n",
    " - En temperatura cero si la mayoría de los spins apuntan en una dirección, podemos dejar que el sistema evolucione en el tiempo hasta que todos queden apuntando en esa dirección.\n",
    " - Para una temperatura dada, podemos analizar que pasa con el material ferromagnético usando la teoría de campo medio. En el caso ferromagnético con $w_{ij}=\\frac{J}{N}$ nos queda:\n",
    "   \\begin{equation}\n",
    "\t\\langle S \\rangle = tanh(\\beta J\\langle S \\rangle) \n",
    "  \\end{equation}\n",
    "    - Para todos los spins sin la presencia de campo magnético externo.\n",
    "    - Esta ecuación puede ser resuelta gráficamente:\n",
    "    ![ferrofun](images/ferrofun.png)\n",
    " - La solució varia según $\\beta J$ sea mayor o menor a 1.\n",
    " - Esto hace que haya una temperatura crítica a partir de la cual la media del valor spin se hace cero \n",
    " \\begin{equation}\n",
    "\tT_C=\\frac{J}{\\kappa_B}\n",
    "  \\end{equation}\n",
    "  - El gráfico del valor medio del spin en función de la temperatura (para una de las soluciones) quedaría:\n",
    "  ![temp](images/temp.png)\n",
    "  - Los spins pueden encontrarse predominantemente hacia arriba o hacia abajo cuando $T<T_C$.\n",
    "  - Si $N\\rightarrow\\infty$, entonces el sistema va a permanecer en el estadoe n el que se encuentre.\n",
    "  - Siendo que en general N es lo suficientemente grande, la teoría del campo medio describe correctamente el comportamiento de un material ferromagnético en función de la temperatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes estocásticas\n",
    " - Haremos que el comportamiento de las neuronas de una red de Hopfield sea idéntico al de los spins en el modelo de Issing.\n",
    " - Es decir, reemplazaremos la función de activación por una función de activación estocástica que cumpla con:\n",
    " \\begin{equation}\n",
    " Prob(S_i = \\pm1)=f_\\beta(\\pm h_i)=\\frac{1}{1+exp(\\mp2\\beta h_i)}\n",
    " \\end{equation}\n",
    "   - Para la neurona i seleccionada en forma aleatoria para ser actualizara.\n",
    " - Se puede definir uns pseudo-temperatura de la red como: $\\beta \\equiv \\frac{1}{T}$\n",
    " - Dicha temperatura modifica la pendiente de la sigmoidea alrededor de h=0.\n",
    "   - A baja temperatura la sigmoidea se transforma en una función escalón y nos queda una red determinística.\n",
    "   - A medida que sube la temperatura la pendiente es cada vez menos pronunciada.\n",
    " - El uso de unidades estocásticas no solos nos permite modelar el comportamiento de una red neuronal real, sino que es útil en muchas situaciones ya que veremsos que nos permite eliminar varios mínimos locales de la función de enrgía pertenecientes a estados espurios.\n",
    "   - En general los mínimos correspondientes a estados espurios tienen mayor energía (menor estabilidad) que los patrones almacenados.\n",
    " - En base a esto, debemos analizar los los estaos de equilibrio de una red nauronal, esto es, aplicar el concepto de teoría de campo medio para ver qué pasa con cada una de las neuronas a medida que el sistema evoluciona.\n",
    "   - Se puede probar que una red de pesos simétricos con función de energía asociada, tiene de a converger a un estado de equilibrio.\n",
    " - Si bien no podemos hablar de configuraciones estables en función de valores determinísiticos de $S_i$, si podemos ver en que valores medidos de $S_i$ se estabiliza cada una de las neuronas.\n",
    " ### Redes estocásticas (Teoría de campo medio)\n",
    " - Nos mantendremos en el casop de $p<<N$ o bien $N\\rightarrow \\infty$.\n",
    " - Podemos escribir las ecuaciones de campo medio como:\n",
    "   \\begin{equation}\n",
    "\t\\langle S_i \\rangle = tanh(\\frac{\\beta}{N}\\sum_{i,\\mu}𝜉_{i}^{\\mu}𝜉_{j}^{\\mu} \\langle S_i \\rangle)\n",
    "  \\end{equation}\n",
    "   - La solución es muy difícil de obtener ya que tenemos un sistema de N ecuaciones no lineales con N incógnitas.\n",
    " - Siguiendo el ejemplo del material ferromagnético podemos suponer que:\n",
    " \\begin{equation}\n",
    "\t\\langle S_i \\rangle =m𝜉_{i}^{\\nu}\n",
    "  \\end{equation}\n",
    "   - Es una solución del sistema de ecuaciones.\n",
    "   - Es decir, una de las soluciones es proporcional a uno de los patrones almacenados.\n",
    " - Ya vimos que en el caso de la red determinística esto es cierto y con m=1.\n",
    " - Siguiendo la suposición, podemos escribir:\n",
    "    \\begin{equation}\n",
    "\tm𝜉_{i}^{\\nu} = tanh(\\frac{\\beta}{N}\\sum_{i,\\mu}𝜉_{i}^{\\mu}𝜉_{j}^{\\mu}m𝜉_j^{\\nu})\n",
    "  \\end{equation}\n",
    "  - Como en el de la red estocástica podemos escribir la sumatoria como un término proporcional a $𝜉_{i}^{\\nu}$ mas un crosstalk term tiende a cero y nos queda:\n",
    "   \\begin{equation}\n",
    "\tm𝜉_{i}^{\\nu} = tanh(\\beta m 𝜉_j^{\\nu})\n",
    "  \\end{equation}\n",
    "- Pero como tanh es una función impar, podemos escribir independientemente del valor de $𝜉_j^{\\nu}$ : \n",
    "   \\begin{equation}\n",
    "\tm = tanh(\\beta m )\n",
    "  \\end{equation}\n",
    "- Esto es muy similar a lo que encontramos en el caso de la magnetización de un ferromagnético, por lo que podemos resolver de la misma manera (en forma gráfica); por lo tanto la temperatura crítica es igual a $T_C$ es igual a 1 para una red estocástica con $p<<N$.\n",
    "- Adaptando el problema de Issing a una red neuronal, podemos escribir:\n",
    "   \\begin{equation}\n",
    "   m = \\frac{\\langle S_i \\rangle}{𝜉_j^{\\nu}}=\\text{Prob(bit is correct)} - \\text{Prob(bit is incorrect)}\n",
    "  \\end{equation}\n",
    "- Y por lo tanto el número promedio de bits correctos es:\n",
    "   \\begin{equation}\n",
    "   \\langle N_correct \\rangle = \\frac{1}{2}N(1+m)\n",
    "  \\end{equation}\n",
    "- Lo podemos graficar en función de de la temperatura:\n",
    "![temp2](images/temp2.png)\n",
    "- Si bien se eliminan estados espurios de mayor energía, otros estados como los inversos permanecen en la red.\n",
    "- Los estados mixtos siguen presente, pero cada uno con una temperatura crítica distinta a partir de la cual deja de ser estable.\n",
    "- La temperatura más alta a partir de la cual los estados mixtos dejan de ser estables es la correspondiente a 3 estados mezclados. Dicha temperatura vale T=0.46.\n",
    "- Esto muestra como el ruido (a través del concepto de temperatura) mejora la performance de la red.\n",
    "- La siguiente figura muestra esquemáticamente cómo varía la función de energía al aumentar la temperatura de la red:\n",
    "![espures](images/espureos.png)\n",
    "- Nótese que el análisis de teoría de campo medio es independiente del modo de actualización (ya sea sincrónica o asincrónica) ya que se independeiza de la dinámica temporal.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (OpLaDyn)",
   "language": "python",
   "name": "opladyn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

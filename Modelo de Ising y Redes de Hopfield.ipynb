{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Ising y redes de Hopfield\n",
    "\n",
    "Las contribuciones mas importantes que hizo John Hopfield al modelo de memoria asociativa visto anteriormente surgen a que dicho modelo es casi id√©ntico matem√°ticamente al problema de Ising. \n",
    "\n",
    "El modelo de Ising es un modelo f√≠sico propuesto para estudiar el comportamiento de materiales ferromagn√©ticos.  Su nombre se debe al f√≠sico Ernst Ising.\n",
    "\n",
    "Hopfield estableci√≥n un analog√≠a entre el modelo de memoria asociativa y el de Ising, trasladando algunas propiedades matem√°ticas del ya conocido modelo de Ising al problema de la memoria asociativa. Es por ello que nos vamos a detener a mirar, aunque sea superficialmente, algunas de las particularidades del modelo de Ising.\n",
    "\n",
    "Para un material ferromagn√©tico:\n",
    "\n",
    "- Se pueden representar como un conjunto de dipolos magn√©ticos de tama√±o at√≥mico, dispuestos de acuerdo a una estructura cristalina. A cada dipolo lo llamaremos SPIN.\n",
    "- Cada spin podr√° estar alineado en dos direcciones posibles.\n",
    "- cada spin ser√° identificado por una variable $S_i$. Si el spin i est√° orientado hacia arriba, entonces $S_i=1$. Si el spin i est√° orientado hacia abajo $S_i=-1$\n",
    "- La representaci√≥n gr√°fica de un material ferromagn√©tico de 4 spins nos quedar√° de la siguiente forma:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Ising-rep.png\" alt=\"drawing\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para la red neuronal an√°loga, una neurona activada equivale a un spin +1 y una neurona desactivada un spin -1.\n",
    "\n",
    "* El comportamiento de cada spin queda definido por el campo magn√©tico existente en su ubicaci√≥n, el cual est√° compuesto por el campo generado por los otros spins (campo interno), mas la contribuci√≥n de un posible campo magn√©tico externo.\n",
    "* Dichas contribuciones sobre el spin i pueden ser expresadas como:\n",
    "\\begin{equation} \n",
    "h_i =   \\sum_{j} w_{ij} S_{j}+ h^{ext}\n",
    "\\end{equation}\n",
    "    * Donde cada coeficiente $w_{ij}$ miden la influencia de cada spin j sobre el spin i. En un material magn√©tico estos coeficientes son sim√©tricos.\n",
    "* El campo magn√©tico $h_i$ a bajas temperaturas define la din√°mica del spin i ya que el spin tiende a alinearse seg√∫n la direcci√≥n de $h_i$.\n",
    "   * Por lo tanto el valor de $S_i = sgn(h_i)$\n",
    "* Otra forma de definir la interacci√≥n de los spins es a trav√©s de la energ√≠a potencial vinculada a esa interacci√≥n. Para un material magn√©tico cuyos spins est√°n influenciados seg√∫n $\\omega_{ij}$, su energ√≠a potencial es:\n",
    "\\begin{equation} \n",
    "H =  -\\frac{1}{2} \\sum_{ij} w_{ij} S_{i}S_{j}- h^{ext}\\sum_{i}S_i\n",
    "\\end{equation}\n",
    "* Por lo tanto la analog√≠a con una red de Hopfield es completa\n",
    "   * Los coeficientes de interacci√≥n entre los spins son los pesos\n",
    "   * La entrada a una neurona corresponde al estado de cada uno de los spins.\n",
    "   * La suma resultante de la interacci√≥n de todos los spins j en un spin i mas el campo externo, corresponde a la salida del combinador lineal.\n",
    "* Se puede pensar que cada vez que agrego un patr√≥n a un a red de hopfield, estoy agregando un nuevo m√≠nimo a la funci√≥n de energ√≠a (mas otros m√≠nimos que aparecen como estados espurios almacenados).\n",
    "* Otra propiedad de la funci√≥n de energ√≠a en el modelo de Ising es que cada vez que actualizo un spin en particular en forma asincr√≥nica, la energ√≠a se mantiene o disminuye. En particular para el modelo de Ising $w_{ii}=0$.\n",
    "    * Si actualizo $S_k$ y $S_k^{t+1}=S_k^{t}$: La energ√≠a se mantiene constante\n",
    "    * Si actualizo $S_k$ y $S_k^{t+1}=-S_k^{t}$:\n",
    "$$ H^{t+1}-H^{t}= -\\frac{1}{2} \\sum_{i} w_{ik} S_{i}S_{k}^{t+1} -\\frac{1}{2} \\sum_{j} w_{kj} S_{k}^{t+1}S_{j}- h^{ext}S_k^{t+1} +\\frac{1}{2} \\sum_{i} w_{ik} S_{i}S_{k}^{t} +\\frac{1}{2} \\sum_{j} w_{kj} S_{k}^{t}S_{j}+ h^{ext}S_k^{t} $$\n",
    "$$ =-\\sum_{i} w_{ik} S_{i}S_{k}^{t+1} - h^{ext}S_k^{t+1}+\\sum_{i} w_{ik} S_{i}S_{k}^{t}+h^{ext}S_k^{t} $$\n",
    "        * Como $S_k$ y $S_k^{t+1}=-S_k^{t}$:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ H^{t+1}-H^{t}= -S_{k}^{t+1} [\\sum_{i} w_{ik} S_{i} + h^{ext}] + S_{k}^{t} [\\sum_{i} w_{ik} S_{i} + h^{ext}]$$\n",
    "$$  H^{t+1}-H^{t} = (-S_{k}^{t+1} + S_{k}^{t}) [\\sum_{i} w_{ik} S_{i} + h^{ext}] = -2 S_{k}^{t+1} [\\sum_{i} w_{ik} S_{i} + h^{ext}] $$\n",
    "\n",
    "* Como $h_k^{t+1}=\\sum_{i} w_{ik} S_{i} + h^{ext}$, y el signo de $h_k^{t+1}$ va a ser igual al de $S_{k}^{t+1}$, el primer t√©rmino es siempre negativo ya que $S_{k}^{t+1}*h_k^{t+1}$ es siempre positivo. \n",
    "    * De manera an√°loga se puede ver que el segundo t√©rmino tambi√©n es siempre negativo.\n",
    "    * Por lo tanto, la energ√≠a de la red cuando se realiza actualizaci√≥n asincr√≥nica, solo puede mantenerse (el spin no cambi√≥) o disminuir(el spin cambi√≥)\n",
    "    * Adem√°s, actualizar en forma sincr√≥nica puede conducir a estados oscilatorio:\n",
    "    \n",
    "    Insertar ejemplo\n",
    "    \n",
    "Una vez vista la analog√≠a con el modelo de Ising, sigamos adelante con el an√°lisis de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estabilidad de un patr√≥n\n",
    "\n",
    "### Condici√≥n de estabilidad\n",
    "\n",
    "Normalmente, se espera que si se entrena con un patr√≥n, el mismo deber√≠a ser igual a la salida, ya que se entren√≥ justamente la red para que eso pase. Dicho de otra forma, se debe cumplir:\n",
    "\n",
    "$ sign(h_i^\\nu) = ùúâ_i^\\nu $ para todo i\n",
    "\n",
    "Donde $h_i^\\nu = \\sum_{j} w_{ij}^\\mu ùúâ_j^\\nu$ que es lo que resulta de entrenar la red de hopfield con un patr√≥n ($ùúâ$).\n",
    "\n",
    "Desarrollando los pesos $w$ se llega a que:\n",
    "\n",
    "$$ h_i^\\nu = \\frac{1}{N} \\sum_{j}\\sum_{\\mu} ùúâ_{i}^\\mu ùúâ_{j}^{\\mu} ùúâ_j^\\nu $$\n",
    "\n",
    "Sacamos finalmente factor com√∫n:\n",
    "\n",
    "\\begin{equation} \n",
    "h_i^\\nu = ùúâ_i^\\nu + \\frac{1}{N} \\sum_{j}\\sum_{\\mu \\neq \\nu} ùúâ_{i}^\\mu ùúâ_{j}^{\\mu} ùúâ_j^\\nu \n",
    "\\end{equation}\n",
    "\n",
    "De la √∫ltima ecuaci√≥n se deduce que si el t√©rmino de la derecha, es nulo, se cumple la condici√≥n de estabilidad.\n",
    "De hecho, gracias a la funci√≥n signo que se debe aplicar sobre $h_i^\\nu$, se puede ser menos restrictivo con el t√©rmino de la derecha y se puede decir que para que cumpla estabilidad debe darse la siguiente igualdad:\n",
    "\n",
    "\\begin{equation} \n",
    "    -ùúâ_i^\\nu \\frac{1}{N} \\sum_{j}\\sum_{\\mu \\neq \\nu} ùúâ_{i}^\\mu ùúâ_{j}^{\\mu} ùúâ_j^\\nu < 1 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacidad de la red\n",
    "\n",
    "Definiremos entonces la siguiente magnitud:\n",
    "\n",
    "$$ C_i^\\nu = ùúâ_i^\\nu \\frac{1}{N} \\sum_{j}\\sum_{\\mu \\neq \\nu} ùúâ_{i}^\\mu ùúâ_{j}^{\\mu} ùúâ_j^\\nu $$\n",
    "\n",
    "De la condici√≥n de estabilidad vista anteriormente.\n",
    "Si $ C_i^\\nu > 1 $ entonces tendremos un bit erroneo en la salida. Es decir, si se ingresa a la red con un patr√≥n de entrenamiento, a la salida se obtendr√° un patr√≥n distinto al deseado.\n",
    "\n",
    "$ C_i^\\nu $ depende √∫nicamente de los patrones que queremos almacenar y de su cantidad. Si consideramos patrones de entrenamiento con igual ocurrencia de $  ùúâ_{i}^\\mu = 1 $ y $  ùúâ_{i}^\\mu = -1 $ entonces se puede calcular que la probablidad de que un bit sea inestable es:\n",
    "\n",
    "$$ P_{error} = Prob(C_i^\\nu > 1) $$\n",
    "\n",
    "Calculemos ùëÉ_ùëíùëüùëüùëúùëü:\n",
    "- N es la cantidad de bits de la entrada/salida.\n",
    "- p es la cantidad de patrones almacenados.\n",
    "\n",
    "_Nota:_ Suponemos que N y p >> 1 (es una condici√≥n aceptable y simplificar√° la matem√°tica).\n",
    "\n",
    "$ ùê∂_ùëñ^ùúà $ es 1/N veces la suma de N*p (N*(p-1) para ser exactos) n√∫meros aleatorios independientes que valen 1 o -1. Distribuci√≥n de una suma de N*p valores que pueden valer 1 o -1 con p=0.5.\n",
    "\n",
    "Este problema puede ser modelado con una distribuci√≥n binomial de media cero y varianza $ùúé^2=ùëù/ùëÅ$, pero por ser una suma de N t√©rminos, para $N*p>30$ puede ser modelado con una distribuci√≥n gaussiana, vali√©ndonos del Teorema del L√≠mite Central:\n",
    "\n",
    "![gauss](images/gaus.png)\n",
    "\n",
    "La siguiente tabla muestra las relaciones de p/N para obtener distintas probabilidades de error:\n",
    "![gauss](images/tablaerrores.png)\n",
    "\n",
    "Se puede interpretar √©stos resultados siendo que cuanto m√°s grandes sean los patrones (N mayor) mayor ser√° la matr√≠z de Hopfield y mayor su capacidad. Por el contrario, cuantos m√°s patrones se deseen agregar (p), m√°s aumentar√° su probabilidad de error.\n",
    "\n",
    "Elizabeth Gardner demostr√≥ en los '80 que el l√≠mite te√≥rico de alacenamiento de datos en un patr√≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estados Esp√∫rios\n",
    "\n",
    "Adem√°s de almacenar un patr√≥n inverso, hay otros patrones que funcionan como atractores. Dicho atractor que no es ni el patr√≥n mismo ni el patr√≥n inverso se lo denomina como est√°do esp√∫reo.\n",
    "Un ejemplo de patr√≥n esp√∫reo, surge de hacer la cominaci√≥n lineal de un n√∫mero impar de patrones de entrenamiento, por ejemplo:\n",
    "\\begin{equation} \n",
    "ùúâ_i^{mix} = sgn(\\pmùúâ_i^{\\mu_1}\\pmùúâ_i^{\\mu_2}\\pmùúâ_i^{\\mu_3})\n",
    "\\end{equation}\n",
    "\n",
    "Para un valor de $ùúâ_i^{\\mu_1}$ dado $ùúâ_i^{mix}$ tendr√° el mismo signo 3 de las 4 combinaciones posibles de $ùúâ_i^{\\mu_2}$ y $ùúâ_i^{\\mu_3}$ por lo tanto $ùúâ_i^{mix}$ estar√° a una distancia de Hamming N/4 de $ùúâ_i^{\\mu_1}$. un razonamiento an√°logo nos lleva a que la distancia de Hamming de $ùúâ_i^{mix}$ con respecto a $ùúâ_i^{\\mu_2}$ y $ùúâ_i^{\\mu_3}$ tambi√©n es N/4.\n",
    "\n",
    "Esto implica que el producto escalar entre $ùúâ_i^{mix}$ y $ùúâ_i^{\\mu_1}$ valga N/2.\n",
    "\n",
    "Por lo tanto, nos queda:\n",
    "\\begin{equation} \n",
    "h_i^{mix} =  \\frac{1}{N} \\sum_{j\\mu} ùúâ_{i}^\\mu ùúâ_{j}^{\\mu} ùúâ_j^{mix} = \\frac{1}{2}ùúâ_i^{\\mu_2}+\\frac{1}{2}ùúâ_i^{\\mu_3}+crossterms\n",
    "\\end{equation}\n",
    "\n",
    "Los cross-terms tienen la particularidad estad√≠stica (distribuaci√≥n binamial) analizada anteriormente, por lo que la ecuaci√≥n anterior cumple con el criterio de estabilidad. Por lo tanto $ùúâ_i^{mix}$ es un patr√≥n almacenado en la red.\n",
    "\n",
    "Adem√°s Amit (1985) demostr√≥ que existen otros estados esp√∫reos en la red que no guardan correlaci√≥n con los estados ya almacenados.\n",
    "\n",
    "Por lo tanto, la red de Hopfield est√° limitada no solo por la probabilidad del error de bit, sino que adm√°s por la existencia de estados esp√∫reos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efecto de la temperatura en el modelo de Issing\n",
    " - El modelo anterior aplica solamente a temperaturas muy bajas, cercanas al 0 K.\n",
    " - Para temeraturas m√°s altas, el comportamiento de los spins se vuelve estoc√°stico y su estado de alineaci√≥n esta determinado por: $S_i = +1$ on probabilidad $g(h_i)$ y $S_i$ con probabilidad $1-g(h_i)$.\n",
    " - La funci√≥n $g(h_i)$ depende de la temperatura del sistema:\n",
    "\\begin{equation} \n",
    "g(h) = f_\\beta(h)\\equiv \\frac{1}{1+exp(-2\\beta h)}\n",
    "\\end{equation}\n",
    " - Ya que $\\beta=\\frac{1}{\\kappa_B T}$, donde $\\kappa_B$ es la constante de Boltzmann y vale $1.38*10^{16\\frac{erg}{K}}$.\n",
    " - Dado que: $1-f_\\beta(h)=f_\\beta(-h)$, podemos escribir: $Prob(S_i = \\pm1)=f_\\beta(\\pm h_i)=\\frac{1}{1+exp(\\mp2\\beta h_i)}$\n",
    " - La temperatura regula qu√© tan abrupta es la variaci√≥n de la pdf alrededor de h=0.\n",
    " - A medida que $T\\rightarrow0$, vemos como el modelo estoc√°stico se reduce al modelo determin√≠stico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estado de equilibrio de un spin\n",
    " - Vamos a analizar cual es la magnetizaci√≥n promedio de un material ferromagn√©tico.\n",
    " - Para empezar, supongamos que tenemos un material ferromagn√©tico de un solo spin.\n",
    "   - Esto implicar√° que el √∫nico campo magn√©tico ser√° el externo.\n",
    "   - Su valor promedio tendr√° la forma:\n",
    "\\begin{equation}\n",
    "\t\\langle S \\rangle = Prob(+1).(+1)+ Prob(-1).(-1) \\\\\n",
    "    = \\frac{1}{1+e^{-2\\beta h}}-\\frac{1}{1+e^{2\\beta h}}=\\frac{e^{\\beta h}}{e^{\\beta h}+e^{-\\beta h}}-\\frac{e^{-\\beta h}}{e^{-\\beta h}+e^{\\beta h}} \\\\\n",
    "    =tangh(\\beta h)\n",
    "\\end{equation}\n",
    " - La tanh tiene la misma forma que la distribuci√≥n de probabilidades, pero varia entre -1 y 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teror√≠a del campo medio\n",
    " - Ahora queremos analizar que pasa en un material ferromagn√©tico con m√°s de un spin.\n",
    " - La evoluci√≥n del estado de un spin i depende de:\n",
    "\\begin{equation}\n",
    " h_i=\\sum_i w_{ij}S_j+h^{ext}\n",
    "\\end{equation}\n",
    "   - Lo cual involucra variables S_j que fluctu√°n en el tiempo.\n",
    "  - Como el an√°lisis de un material ferromagn√©tico es muy complejo, se utiliza la teor√≠a del campo medio para analizar el comportamiento de material y su magnetizaci√≥n promedio.\n",
    "  - M√°s all√° del inter√©s que pueda tener f√≠sicamente este an√°lisis, m√°s adelante noss brindar√° una herramienta m√°s para analizar redes neuoronales.\n",
    "  - La idea consiste en reemplazar a cada uno de los $h_i$ resultantes en  cada spin, por su valor medio:\n",
    "  \\begin{equation}\n",
    "\t\\langle h_i \\rangle =\\sum_j w_{ij}\\langle S_j \\rangle + h^{ext}\n",
    "   \\end{equation}\n",
    "  - El mismo depende de los valores promedios de los spins del material.\n",
    "  - A partir de lo visto en \"Esta de equilibrio de un spin\" podemos calcular los valores de campo magn√©tico de cada spin del material como:\n",
    "  \\begin{equation}\n",
    "\t\\langle S_i \\rangle = tanh(\\beta \\langle h_i \\rangle) = tanh(\\beta\\sum_j w_{ij}\\langle S_j \\rangle +\\beta h^{ext})\n",
    "  \\end{equation}\n",
    "    - Lo cual nos da N ecuaciones no lineales con N inc√≥gnitas, pero sin que en ning√∫n lado aparezcan variables aleatorias.\n",
    "  - La idea es reemplazar todos los spins salvo por sus valores medios, de esta forma podemos analizar como evoluciona un spin en particular.\n",
    "  - A medida que la cantidad de spins aumenta, este modelo se vuelve cada vez m√°s preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Material ferromagn√©tico\n",
    " - Todos los $w_{ij}$ son positivos. Esto hace que todos los spins tiendan a alinearse los unos a los otros.\n",
    " - A partir de cierta temperatura $T_C$, sin campo externo,$\\langle S \\rangle =0$. Por debajo de esa temperatura $T_C,\\langle S \\rangle \\neq 0$\n",
    "   - Por ejemplo el hierro pierde sus propiedades magn√©ticas a 770 grados.\n",
    " - El modelo m√°s sencillo de material ferromagn√©tico est√° dado por $w_{ij}=\\frac{J}{N}$\n",
    "   - Para un ferromagn√©tico de N spins.\n",
    "   - Este modelo tiene su an√°logo en la red de Hopfield. Si J=1, corresponde a un solo patr√≥n almacenado, cuyos bits valen todos 1.\n",
    "   - Es decir. hay dos atractores, uno con todos los valores en 1 y otro con todos los valores en -1. Dicho de otra forma, todos los spins alineados hacia arriaba y todos los spins alineados hacia abajo.\n",
    "   - Si hablamos de una red con varios patrones almacenados, el fen√≥meno es como si habl√°ramos de un material ferromagn√©tico cuyos valores de spins estables ya no son todos 1 o todos -1, sino que aparecen otras opciones.\n",
    " - En temperatura cero si la mayor√≠a de los spins apuntan en una direcci√≥n, podemos dejar que el sistema evolucione en el tiempo hasta que todos queden apuntando en esa direcci√≥n.\n",
    " - Para una temperatura dada, podemos analizar que pasa con el material ferromagn√©tico usando la teor√≠a de campo medio. En el caso ferromagn√©tico con $w_{ij}=\\frac{J}{N}$ nos queda:\n",
    "   \\begin{equation}\n",
    "\t\\langle S \\rangle = tanh(\\beta J\\langle S \\rangle) \n",
    "  \\end{equation}\n",
    "    - Para todos los spins sin la presencia de campo magn√©tico externo.\n",
    "    - Esta ecuaci√≥n puede ser resuelta gr√°ficamente:\n",
    "    ![ferrofun](images/ferrofun.png)\n",
    " - La soluci√≥ varia seg√∫n $\\beta J$ sea mayor o menor a 1.\n",
    " - Esto hace que haya una temperatura cr√≠tica a partir de la cual la media del valor spin se hace cero \n",
    " \\begin{equation}\n",
    "\tT_C=\\frac{J}{\\kappa_B}\n",
    "  \\end{equation}\n",
    "  - El gr√°fico del valor medio del spin en funci√≥n de la temperatura (para una de las soluciones) quedar√≠a:\n",
    "  ![temp](images/temp.png)\n",
    "  - Los spins pueden encontrarse predominantemente hacia arriba o hacia abajo cuando $T<T_C$.\n",
    "  - Si $N\\rightarrow\\infty$, entonces el sistema va a permanecer en el estadoe n el que se encuentre.\n",
    "  - Siendo que en general N es lo suficientemente grande, la teor√≠a del campo medio describe correctamente el comportamiento de un material ferromagn√©tico en funci√≥n de la temperatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes estoc√°sticas\n",
    " - Haremos que el comportamiento de las neuronas de una red de Hopfield sea id√©ntico al de los spins en el modelo de Issing.\n",
    " - Es decir, reemplazaremos la funci√≥n de activaci√≥n por una funci√≥n de activaci√≥n estoc√°stica que cumpla con:\n",
    " \\begin{equation}\n",
    " Prob(S_i = \\pm1)=f_\\beta(\\pm h_i)=\\frac{1}{1+exp(\\mp2\\beta h_i)}\n",
    " \\end{equation}\n",
    "   - Para la neurona i seleccionada en forma aleatoria para ser actualizara.\n",
    " - Se puede definir uns pseudo-temperatura de la red como: $\\beta \\equiv \\frac{1}{T}$\n",
    " - Dicha temperatura modifica la pendiente de la sigmoidea alrededor de h=0.\n",
    "   - A baja temperatura la sigmoidea se transforma en una funci√≥n escal√≥n y nos queda una red determin√≠stica.\n",
    "   - A medida que sube la temperatura la pendiente es cada vez menos pronunciada.\n",
    " - El uso de unidades estoc√°sticas no solos nos permite modelar el comportamiento de una red neuronal real, sino que es √∫til en muchas situaciones ya que veremsos que nos permite eliminar varios m√≠nimos locales de la funci√≥n de enrg√≠a pertenecientes a estados espurios.\n",
    "   - En general los m√≠nimos correspondientes a estados espurios tienen mayor energ√≠a (menor estabilidad) que los patrones almacenados.\n",
    " - En base a esto, debemos analizar los los estaos de equilibrio de una red nauronal, esto es, aplicar el concepto de teor√≠a de campo medio para ver qu√© pasa con cada una de las neuronas a medida que el sistema evoluciona.\n",
    "   - Se puede probar que una red de pesos sim√©tricos con funci√≥n de energ√≠a asociada, tiene de a converger a un estado de equilibrio.\n",
    " - Si bien no podemos hablar de configuraciones estables en funci√≥n de valores determin√≠siticos de $S_i$, si podemos ver en que valores medidos de $S_i$ se estabiliza cada una de las neuronas.\n",
    " ### Redes estoc√°sticas (Teor√≠a de campo medio)\n",
    " - Nos mantendremos en el casop de $p<<N$ o bien $N\\rightarrow \\infty$.\n",
    " - Podemos escribir las ecuaciones de campo medio como:\n",
    "   \\begin{equation}\n",
    "\t\\langle S_i \\rangle = tanh(\\frac{\\beta}{N}\\sum_{i,\\mu}ùúâ_{i}^{\\mu}ùúâ_{j}^{\\mu} \\langle S_i \\rangle)\n",
    "  \\end{equation}\n",
    "   - La soluci√≥n es muy dif√≠cil de obtener ya que tenemos un sistema de N ecuaciones no lineales con N inc√≥gnitas.\n",
    " - Siguiendo el ejemplo del material ferromagn√©tico podemos suponer que:\n",
    " \\begin{equation}\n",
    "\t\\langle S_i \\rangle =mùúâ_{i}^{\\nu}\n",
    "  \\end{equation}\n",
    "   - Es una soluci√≥n del sistema de ecuaciones.\n",
    "   - Es decir, una de las soluciones es proporcional a uno de los patrones almacenados.\n",
    " - Ya vimos que en el caso de la red determin√≠stica esto es cierto y con m=1.\n",
    " - Siguiendo la suposici√≥n, podemos escribir:\n",
    "    \\begin{equation}\n",
    "\tmùúâ_{i}^{\\nu} = tanh(\\frac{\\beta}{N}\\sum_{i,\\mu}ùúâ_{i}^{\\mu}ùúâ_{j}^{\\mu}mùúâ_j^{\\nu})\n",
    "  \\end{equation}\n",
    "  - Como en el de la red estoc√°stica podemos escribir la sumatoria como un t√©rmino proporcional a $ùúâ_{i}^{\\nu}$ mas un crosstalk term tiende a cero y nos queda:\n",
    "   \\begin{equation}\n",
    "\tmùúâ_{i}^{\\nu} = tanh(\\beta m ùúâ_j^{\\nu})\n",
    "  \\end{equation}\n",
    "- Pero como tanh es una funci√≥n impar, podemos escribir independientemente del valor de $ùúâ_j^{\\nu}$ : \n",
    "   \\begin{equation}\n",
    "\tm = tanh(\\beta m )\n",
    "  \\end{equation}\n",
    "- Esto es muy similar a lo que encontramos en el caso de la magnetizaci√≥n de un ferromagn√©tico, por lo que podemos resolver de la misma manera (en forma gr√°fica); por lo tanto la temperatura cr√≠tica es igual a $T_C$ es igual a 1 para una red estoc√°stica con $p<<N$.\n",
    "- Adaptando el problema de Issing a una red neuronal, podemos escribir:\n",
    "   \\begin{equation}\n",
    "   m = \\frac{\\langle S_i \\rangle}{ùúâ_j^{\\nu}}=\\text{Prob(bit is correct)} - \\text{Prob(bit is incorrect)}\n",
    "  \\end{equation}\n",
    "- Y por lo tanto el n√∫mero promedio de bits correctos es:\n",
    "   \\begin{equation}\n",
    "   \\langle N_correct \\rangle = \\frac{1}{2}N(1+m)\n",
    "  \\end{equation}\n",
    "- Lo podemos graficar en funci√≥n de de la temperatura:\n",
    "![temp2](images/temp2.png)\n",
    "- Si bien se eliminan estados espurios de mayor energ√≠a, otros estados como los inversos permanecen en la red.\n",
    "- Los estados mixtos siguen presente, pero cada uno con una temperatura cr√≠tica distinta a partir de la cual deja de ser estable.\n",
    "- La temperatura m√°s alta a partir de la cual los estados mixtos dejan de ser estables es la correspondiente a 3 estados mezclados. Dicha temperatura vale T=0.46.\n",
    "- Esto muestra como el ruido (a trav√©s del concepto de temperatura) mejora la performance de la red.\n",
    "- La siguiente figura muestra esquem√°ticamente c√≥mo var√≠a la funci√≥n de energ√≠a al aumentar la temperatura de la red:\n",
    "![espures](images/espureos.png)\n",
    "- N√≥tese que el an√°lisis de teor√≠a de campo medio es independiente del modo de actualizaci√≥n (ya sea sincr√≥nica o asincr√≥nica) ya que se independeiza de la din√°mica temporal.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (OpLaDyn)",
   "language": "python",
   "name": "opladyn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
